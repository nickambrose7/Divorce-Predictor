{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to Try and Fix Feature Importance issues\n",
    "\n",
    "\n",
    "#### Initialize the Dataframe and Process the Data - Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the summary statistics for the features:\n",
      "               Age        Fare\n",
      "count  712.000000  712.000000\n",
      "mean    29.642093   34.567251\n",
      "std     14.492933   52.938648\n",
      "min      0.420000    0.000000\n",
      "25%     20.000000    8.050000\n",
      "50%     28.000000   15.645850\n",
      "75%     38.000000   33.000000\n",
      "max     80.000000  512.329200\n",
      "--------------------------------------------------------------------\n",
      "This is the number of rows in the dataset: 712\n",
      "--------------------------------------------------------------------\n",
      "This is the number of unique values in each column:\n",
      " Age               88\n",
      "Fare             219\n",
      "Pclass_1           2\n",
      "Pclass_2           2\n",
      "Pclass_3           2\n",
      "Sex_female         2\n",
      "Sex_male           2\n",
      "SibSp_0            2\n",
      "SibSp_1            2\n",
      "SibSp_2            2\n",
      "SibSp_3            2\n",
      "SibSp_4            2\n",
      "SibSp_5            2\n",
      "Parch_0            2\n",
      "Parch_1            2\n",
      "Parch_2            2\n",
      "Parch_3            2\n",
      "Parch_4            2\n",
      "Parch_5            2\n",
      "Parch_6            2\n",
      "Embarked_C         2\n",
      "Embarked_Q         2\n",
      "Embarked_S         2\n",
      "CabinLetter_?      2\n",
      "CabinLetter_A      2\n",
      "CabinLetter_B      2\n",
      "CabinLetter_C      2\n",
      "CabinLetter_D      2\n",
      "CabinLetter_E      2\n",
      "CabinLetter_F      2\n",
      "CabinLetter_G      2\n",
      "CabinLetter_T      2\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/j4rx3d1d2md8w8cz828b40jh0000gn/T/ipykernel_9181/1195426193.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  titanic_df['CabinLetter'] = titanic_df['Cabin'].str.slice(0,1)\n"
     ]
    }
   ],
   "source": [
    "# Import titanic data\n",
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Processing features:\n",
    "# 1. Drop columns that are not useful\n",
    "titanic_features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked']\n",
    "titanic_df = titanic[titanic_features]\n",
    "titanic_df['CabinLetter'] = titanic_df['Cabin'].str.slice(0,1)\n",
    "X = titanic_df.drop('Cabin',axis=1)\n",
    "X['CabinLetter'] = X['CabinLetter'].fillna(\"?\")\n",
    "X['Pclass'] = X['Pclass'].astype(str)\n",
    "X['SibSp'] = X['SibSp'].astype(str)\n",
    "X['Parch'] = X['Parch'].astype(str)\n",
    "X = X.dropna()\n",
    "t = titanic.loc[X.index, 'Survived']\n",
    "# 2. Convert categorical features to dummy variables (one-hot encoding with pandas)\n",
    "X = pd.get_dummies(X)\n",
    "# Display summary statistics for the features\n",
    "print(f\"These are the summary statistics for the features:\\n {X.describe()}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of rows in the dataset: {len(X)}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of unique values in each column:\\n {X.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Dataframe and Process the Data - Divorce Dataset\n",
    "\n",
    "Note: The divorce dataset has no missing values and there are exactly 5 unique values per feature (0, 1, 2, 3, 4) that correspond to the following:<br>\n",
    "- 0 - Never\n",
    "- 1 - Seldom\n",
    "- 2 - Averagely\n",
    "- 3 - Frequently\n",
    "- 4 - Always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the summary statistics for the features:\n",
      "                Q1          Q2          Q3          Q4          Q5          Q6  \\\n",
      "count  170.000000  170.000000  170.000000  170.000000  170.000000  170.000000   \n",
      "mean     1.776471    1.652941    1.764706    1.482353    1.541176    0.747059   \n",
      "std      1.627257    1.468654    1.415444    1.504327    1.632169    0.904046   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      2.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
      "75%      3.000000    3.000000    3.000000    3.000000    3.000000    1.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "               Q7          Q8          Q9         Q10  ...         Q45  \\\n",
      "count  170.000000  170.000000  170.000000  170.000000  ...  170.000000   \n",
      "mean     0.494118    1.452941    1.458824    1.576471  ...    2.458824   \n",
      "std      0.898698    1.546371    1.557976    1.421529  ...    1.499925   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000  ...    1.000000   \n",
      "50%      0.000000    1.000000    1.000000    2.000000  ...    3.000000   \n",
      "75%      1.000000    3.000000    3.000000    3.000000  ...    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000  ...    4.000000   \n",
      "\n",
      "              Q46         Q47         Q48         Q49         Q50         Q51  \\\n",
      "count  170.000000  170.000000  170.000000  170.000000  170.000000  170.000000   \n",
      "mean     2.552941    2.270588    2.741176    2.382353    2.429412    2.476471   \n",
      "std      1.371786    1.586841    1.137348    1.511587    1.405090    1.260238   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      2.000000    1.000000    2.000000    1.000000    1.000000    2.000000   \n",
      "50%      3.000000    2.000000    3.000000    3.000000    2.000000    3.000000   \n",
      "75%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "              Q52         Q53         Q54  \n",
      "count  170.000000  170.000000  170.000000  \n",
      "mean     2.517647    2.241176    2.011765  \n",
      "std      1.476537    1.505634    1.667611  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      1.000000    1.000000    0.000000  \n",
      "50%      3.000000    2.000000    2.000000  \n",
      "75%      4.000000    4.000000    4.000000  \n",
      "max      4.000000    4.000000    4.000000  \n",
      "\n",
      "[8 rows x 54 columns]\n",
      "--------------------------------------------------------------------\n",
      "This is the number of rows in the dataset: 170\n",
      "--------------------------------------------------------------------\n",
      "This is the number of unique values in each column:\n",
      " Q1     5\n",
      "Q2     5\n",
      "Q3     5\n",
      "Q4     5\n",
      "Q5     5\n",
      "Q6     5\n",
      "Q7     5\n",
      "Q8     5\n",
      "Q9     5\n",
      "Q10    5\n",
      "Q11    5\n",
      "Q12    5\n",
      "Q13    5\n",
      "Q14    5\n",
      "Q15    5\n",
      "Q16    5\n",
      "Q17    5\n",
      "Q18    5\n",
      "Q19    5\n",
      "Q20    5\n",
      "Q21    5\n",
      "Q22    5\n",
      "Q23    5\n",
      "Q24    5\n",
      "Q25    5\n",
      "Q26    5\n",
      "Q27    5\n",
      "Q28    5\n",
      "Q29    5\n",
      "Q30    5\n",
      "Q31    5\n",
      "Q32    5\n",
      "Q33    5\n",
      "Q34    5\n",
      "Q35    5\n",
      "Q36    5\n",
      "Q37    5\n",
      "Q38    5\n",
      "Q39    5\n",
      "Q40    5\n",
      "Q41    5\n",
      "Q42    5\n",
      "Q43    5\n",
      "Q44    5\n",
      "Q45    5\n",
      "Q46    5\n",
      "Q47    5\n",
      "Q48    5\n",
      "Q49    5\n",
      "Q50    5\n",
      "Q51    5\n",
      "Q52    5\n",
      "Q53    5\n",
      "Q54    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import divorce data\n",
    "divorce = pd.read_csv('data/divorce_data.csv',sep=';')\n",
    "\n",
    "# Processing features:\n",
    "X = divorce.drop('Divorce',axis=1) # .dropna() - dataset has no missing values\n",
    "t = divorce['Divorce']\n",
    "\n",
    "# Display summary statistics for the features\n",
    "print(f\"These are the summary statistics for the features:\\n {X.describe()}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of rows in the dataset: {len(X)}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of unique values in each column:\\n {X.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (113, 54)\n",
      "Train y shape: (113,)\n",
      "Train X summary statistics:\n",
      "                Q1          Q2          Q3          Q4          Q5          Q6  \\\n",
      "count  113.000000  113.000000  113.000000  113.000000  113.000000  113.000000   \n",
      "mean     1.725664    1.522124    1.672566    1.442478    1.460177    0.796460   \n",
      "std      1.604947    1.414828    1.423291    1.511492    1.581339    0.927355   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      2.000000    2.000000    2.000000    1.000000    1.000000    1.000000   \n",
      "75%      3.000000    3.000000    3.000000    3.000000    3.000000    1.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "               Q7          Q8          Q9         Q10  ...         Q45  \\\n",
      "count  113.000000  113.000000  113.000000  113.000000  ...  113.000000   \n",
      "mean     0.477876    1.336283    1.380531    1.530973  ...    2.353982   \n",
      "std      0.835564    1.503630    1.542948    1.414660  ...    1.557931   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000  ...    1.000000   \n",
      "50%      0.000000    0.000000    0.000000    2.000000  ...    3.000000   \n",
      "75%      1.000000    3.000000    3.000000    3.000000  ...    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000  ...    4.000000   \n",
      "\n",
      "              Q46         Q47         Q48         Q49         Q50         Q51  \\\n",
      "count  113.000000  113.000000  113.000000  113.000000  113.000000  113.000000   \n",
      "mean     2.530973    2.221239    2.716814    2.424779    2.442478    2.486726   \n",
      "std      1.401981    1.640636    1.137581    1.462662    1.407493    1.240068   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      2.000000    1.000000    2.000000    1.000000    1.000000    2.000000   \n",
      "50%      3.000000    2.000000    3.000000    3.000000    3.000000    3.000000   \n",
      "75%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "              Q52         Q53         Q54  \n",
      "count  113.000000  113.000000  113.000000  \n",
      "mean     2.557522    2.274336    2.000000  \n",
      "std      1.475624    1.453123    1.642081  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      1.000000    1.000000    0.000000  \n",
      "50%      3.000000    2.000000    2.000000  \n",
      "75%      4.000000    4.000000    4.000000  \n",
      "max      4.000000    4.000000    4.000000  \n",
      "\n",
      "[8 rows x 54 columns]\n",
      "--------------------------------------------------------------------\n",
      "Test X summary statistics:\n",
      "               Q1         Q2         Q3         Q4         Q5         Q6  \\\n",
      "count  57.000000  57.000000  57.000000  57.000000  57.000000  57.000000   \n",
      "mean    1.877193   1.912281   1.947368   1.561404   1.701754   0.649123   \n",
      "std     1.680457   1.550123   1.394134   1.500209   1.731689   0.855470   \n",
      "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "25%     0.000000   0.000000   1.000000   0.000000   0.000000   0.000000   \n",
      "50%     2.000000   2.000000   2.000000   2.000000   1.000000   0.000000   \n",
      "75%     3.000000   3.000000   3.000000   3.000000   3.000000   1.000000   \n",
      "max     4.000000   4.000000   4.000000   4.000000   4.000000   3.000000   \n",
      "\n",
      "              Q7         Q8         Q9        Q10  ...        Q45        Q46  \\\n",
      "count  57.000000  57.000000  57.000000  57.000000  ...  57.000000  57.000000   \n",
      "mean    0.526316   1.684211   1.614035   1.666667  ...   2.666667   2.596491   \n",
      "std     1.019546   1.616410   1.589636   1.443376  ...   1.367131   1.320980   \n",
      "min     0.000000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   \n",
      "25%     0.000000   0.000000   0.000000   0.000000  ...   2.000000   2.000000   \n",
      "50%     0.000000   2.000000   1.000000   2.000000  ...   3.000000   3.000000   \n",
      "75%     1.000000   3.000000   3.000000   3.000000  ...   4.000000   4.000000   \n",
      "max     4.000000   4.000000   4.000000   4.000000  ...   4.000000   4.000000   \n",
      "\n",
      "             Q47        Q48        Q49        Q50        Q51        Q52  \\\n",
      "count  57.000000  57.000000  57.000000  57.000000  57.000000  57.000000   \n",
      "mean    2.368421   2.789474   2.298246   2.403509   2.456140   2.438596   \n",
      "std     1.483620   1.145439   1.614277   1.412440   1.310264   1.488258   \n",
      "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "25%     1.000000   2.000000   1.000000   1.000000   2.000000   1.000000   \n",
      "50%     2.000000   3.000000   3.000000   2.000000   3.000000   3.000000   \n",
      "75%     4.000000   4.000000   4.000000   4.000000   4.000000   4.000000   \n",
      "max     4.000000   4.000000   4.000000   4.000000   4.000000   4.000000   \n",
      "\n",
      "             Q53        Q54  \n",
      "count  57.000000  57.000000  \n",
      "mean    2.175439   2.035088  \n",
      "std     1.616023   1.731689  \n",
      "min     0.000000   0.000000  \n",
      "25%     1.000000   0.000000  \n",
      "50%     3.000000   2.000000  \n",
      "75%     4.000000   4.000000  \n",
      "max     4.000000   4.000000  \n",
      "\n",
      "[8 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Done with sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, t, test_size=0.33, random_state=42)\n",
    "\n",
    "# Print the train X and y shapes\n",
    "print(f\"Train X shape: {train_X.shape}\")\n",
    "print(f\"Train y shape: {train_y.shape}\")\n",
    "\n",
    "# Print the summary statistics of the training features and testing features\n",
    "print(f\"Train X summary statistics:\\n {train_X.describe()}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"Test X summary statistics:\\n {val_X.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Model\n",
    "Here we'll instantiate and train a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m knn_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(val_X)\n\u001b[1;32m      2\u001b[0m original_accuracy \u001b[39m=\u001b[39m accuracy_score(val_y, knn_pred)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe prediction accuracy is: \u001b[39m\u001b[39m{\u001b[39;00moriginal_accuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    244\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_fit_method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m ArgKminClassMode\u001b[39m.\u001b[39;49mis_usable_for(\n\u001b[1;32m    247\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric\n\u001b[1;32m    248\u001b[0m     ):\n\u001b[1;32m    249\u001b[0m         probabilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    250\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_usable_for\u001b[39m(\u001b[39mcls\u001b[39m, X, Y, metric) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    450\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 471\u001b[0m         ArgKmin\u001b[39m.\u001b[39;49mis_usable_for(X, Y, metric)\n\u001b[1;32m    472\u001b[0m         \u001b[39m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    474\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(Y)\n\u001b[1;32m    475\u001b[0m         \u001b[39m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m         \u001b[39mand\u001b[39;00m metric \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msqeuclidean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    477\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[1;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[1;32m    104\u001b[0m         \u001b[39mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mint32\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m is_usable \u001b[39m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m     get_config()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39menable_cython_pairwise_dist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[1;32m    116\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[1;32m    117\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    118\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m (np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    119\u001b[0m     \u001b[39mand\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mvalid_metrics()\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m is_usable\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_numpy_c_ordered\u001b[39m(X):\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mflags\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39;49mflags\u001b[39m.\u001b[39;49mc_contiguous\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "knn_pred = knn.predict(val_X)\n",
    "original_accuracy = accuracy_score(val_y, knn_pred)\n",
    "print(f\"The prediction accuracy is: {original_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does Accuracy Change with New Split? YES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Split the data into NEW training and validation sets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_X2, val_X2, train_y2, val_y2 \u001b[39m=\u001b[39m train_test_split(X, t, test_size\u001b[39m=\u001b[39m\u001b[39m0.33\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m knn_pred2 \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(val_X2)\n\u001b[1;32m      4\u001b[0m new_accuracy \u001b[39m=\u001b[39m accuracy_score(val_y2, knn_pred2)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe prediction accuracy is: \u001b[39m\u001b[39m{\u001b[39;00mnew_accuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    244\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_fit_method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m ArgKminClassMode\u001b[39m.\u001b[39;49mis_usable_for(\n\u001b[1;32m    247\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric\n\u001b[1;32m    248\u001b[0m     ):\n\u001b[1;32m    249\u001b[0m         probabilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    250\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_usable_for\u001b[39m(\u001b[39mcls\u001b[39m, X, Y, metric) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    450\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 471\u001b[0m         ArgKmin\u001b[39m.\u001b[39;49mis_usable_for(X, Y, metric)\n\u001b[1;32m    472\u001b[0m         \u001b[39m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    474\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(Y)\n\u001b[1;32m    475\u001b[0m         \u001b[39m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m         \u001b[39mand\u001b[39;00m metric \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msqeuclidean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    477\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[1;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[1;32m    104\u001b[0m         \u001b[39mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mint32\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m is_usable \u001b[39m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m     get_config()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39menable_cython_pairwise_dist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[1;32m    116\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[1;32m    117\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    118\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m (np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    119\u001b[0m     \u001b[39mand\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mvalid_metrics()\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m is_usable\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_numpy_c_ordered\u001b[39m(X):\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mflags\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39;49mflags\u001b[39m.\u001b[39;49mc_contiguous\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "# Split the data into NEW training and validation sets\n",
    "train_X2, val_X2, train_y2, val_y2 = train_test_split(X, t, test_size=0.33)\n",
    "knn_pred2 = knn.predict(val_X2)\n",
    "new_accuracy = accuracy_score(val_y2, knn_pred2)\n",
    "print(f\"The prediction accuracy is: {new_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation Feature-Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m val_X_perm[col] \u001b[39m=\u001b[39m val_X[col]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mvalues \u001b[39m# np.random.permutation(val_X_perm[col])\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Make predictions on the new data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m preds \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(val_X_perm)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Compute the accuracy score\u001b[39;00m\n\u001b[1;32m     17\u001b[0m permuted_accuracy \u001b[39m=\u001b[39m accuracy_score(val_y, preds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    244\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_fit_method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m ArgKminClassMode\u001b[39m.\u001b[39;49mis_usable_for(\n\u001b[1;32m    247\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric\n\u001b[1;32m    248\u001b[0m     ):\n\u001b[1;32m    249\u001b[0m         probabilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    250\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_usable_for\u001b[39m(\u001b[39mcls\u001b[39m, X, Y, metric) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    450\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 471\u001b[0m         ArgKmin\u001b[39m.\u001b[39;49mis_usable_for(X, Y, metric)\n\u001b[1;32m    472\u001b[0m         \u001b[39m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    474\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(Y)\n\u001b[1;32m    475\u001b[0m         \u001b[39m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m         \u001b[39mand\u001b[39;00m metric \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msqeuclidean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    477\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[1;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[1;32m    104\u001b[0m         \u001b[39mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mint32\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m is_usable \u001b[39m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m     get_config()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39menable_cython_pairwise_dist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[1;32m    116\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[1;32m    117\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    118\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m (np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    119\u001b[0m     \u001b[39mand\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mvalid_metrics()\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m is_usable\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_numpy_c_ordered\u001b[39m(X):\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mflags\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39;49mflags\u001b[39m.\u001b[39;49mc_contiguous\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "npermutations = 10\n",
    "\n",
    "feature_names = train_X.columns.tolist()\n",
    "importances = {}\n",
    "for col in train_X.columns:\n",
    "    importances[col] = 0\n",
    "\n",
    "# Loop through the features and make predictions on permuted data\n",
    "for col in train_X.columns:\n",
    "    for perm in range(npermutations):\n",
    "        # Permute the column of the validation data\n",
    "        val_X_perm = val_X.copy()\n",
    "        val_X_perm[col] = val_X[col].sample(frac=1, replace=False).values # np.random.permutation(val_X_perm[col])\n",
    "        # Make predictions on the new data\n",
    "        preds = knn.predict(val_X_perm)\n",
    "        # Compute the accuracy score\n",
    "        permuted_accuracy = accuracy_score(val_y, preds)\n",
    "\n",
    "        # Calculate feature importance\n",
    "        importances[col] += original_accuracy - permuted_accuracy\n",
    "    \n",
    "    # Normalize importances\n",
    "    importances[col] /= npermutations\n",
    "\n",
    "display(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Initialize dictionary to store feature importances\u001b[39;00m\n\u001b[1;32m     12\u001b[0m importances \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m Xtrain\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m     14\u001b[0m     importances[col] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39m# Compute the original accuracy\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "## Permutation Feature Importance on the KNN Classifier with all 54 features\n",
    "## (calculated manually - i.e. without sci-kit learn)\n",
    "\n",
    "# Define feature names\n",
    "feature_names = features.columns.tolist()\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays for faster computation\n",
    "X_test = features_test.copy()\n",
    "y_test = target_test.to_numpy()\n",
    "\n",
    "# Initialize dictionary to store feature importances\n",
    "importances = {}\n",
    "for col in Xtrain.columns:\n",
    "    importances[col] = 0\n",
    "\n",
    "# Compute the original accuracy\n",
    "\n",
    "original_accuracy = accuracy_score(y_test.astype(str), target_pred_knn)\n",
    "\"\"\"['0' '1' '0' '1' '0' '0' '0' '1' '0' '1' '1' '0' '0' '1' '1' '0' '1' '0'\n",
    " '1' '0' '1' '1' '1' '1' '1' '0' '1' '0' '1' '1' '1' '1' '0' '0']\"\"\"\n",
    "for i in [0]:#range(X_test.shape[1]):\n",
    "    print(i)\n",
    "    # Permute the ith feature in a copy of the test set\n",
    "    X_test_permuted = X_test.copy()\n",
    "    #print(X_test_permuted[:10, i])\n",
    "    np.random.shuffle(X_test_permuted[:, i])\n",
    "    #print(X_test_permuted[:10, i])\n",
    "\n",
    "    # Make predictions using the permuted data\n",
    "    #print(type(X_test_permuted))\n",
    "    predictions_permuted = knn.predict(X_test_permuted)\n",
    "    #print(predictions_permuted)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy_permuted = accuracy_score(y_test.astype(str), predictions_permuted)\n",
    "    \n",
    "    # Compute the feature importance\n",
    "    importance = original_accuracy - accuracy_permuted\n",
    "    \n",
    "    # Add the feature importance to the list\n",
    "    importances.append(importance)\n",
    "\n",
    "print(importances)\n",
    "\"\"\"\n",
    "# Create a DataFrame to store the results\n",
    "perm_importance_custom_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "perm_importance_custom_df = perm_importance_custom_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "perm_importance_custom_df\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the original featureData: 170\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'featureData1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# randomly split the dataset into two separate datasets\u001b[39;00m\n\u001b[1;32m     14\u001b[0m trainFeatureData \u001b[39m=\u001b[39m featureData\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m trainTargetData \u001b[39m=\u001b[39m targetData[featureData1\u001b[39m.\u001b[39mindex]\n\u001b[1;32m     16\u001b[0m testFeatureData \u001b[39m=\u001b[39m featureData\u001b[39m.\u001b[39mdrop(featureData1\u001b[39m.\u001b[39mindex)\n\u001b[1;32m     17\u001b[0m testTargetData \u001b[39m=\u001b[39m targetData[featureData2\u001b[39m.\u001b[39mindex]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'featureData1' is not defined"
     ]
    }
   ],
   "source": [
    "## Importing the dataset\n",
    "data = pd.read_csv('data/divorce_data.csv', sep=';')\n",
    "\n",
    "#display(data.head())\n",
    "\n",
    "## display the data type of the columns\n",
    "#display(data.dtypes)\n",
    "\n",
    "targetData = data['Divorce']\n",
    "## Making two copies of the data for shuffling\n",
    "featureData = data.copy().drop('Divorce', axis=1)\n",
    "print(f'Length of the original featureData: {len(featureData)}')\n",
    "# randomly split the dataset into two separate datasets\n",
    "trainFeatureData = featureData.sample(frac=0.5, random_state=0)\n",
    "trainTargetData = targetData[featureData1.index]\n",
    "testFeatureData = featureData.drop(featureData1.index)\n",
    "testTargetData = targetData[featureData2.index]\n",
    "print(f'Length of the featureData1: {len(featureData1)}')\n",
    "print(f'Length of the targetData1: {len(targetData1)}')\n",
    "print(f'Length of the featureData2: {len(featureData2)}')\n",
    "print(f'Length of the targetData2: {len(targetData2)}')\n",
    "# check for missing values in the split datasets and print results\n",
    "print(f'Number of missing values in featureData1: {featureData1.isnull().sum().sum()}')\n",
    "print(f'Number of missing values in targetData1: {targetData1.isnull().sum()}')\n",
    "print(f'Number of missing values in featureData2: {featureData2.isnull().sum().sum()}')\n",
    "print(f'Number of missing values in targetData2: {targetData2.isnull().sum()}')\n",
    "\n",
    "# print the indices of the featureData1 and featureData2\n",
    "print(f'featureData1 indices:\\n {featureData1.index}')\n",
    "print(f'featureData2 indices:\\n {featureData2.index}')\n",
    "\n",
    "# shuffle the indices of the featureData1 and featureData2\n",
    "featureData1 = featureData1.sample(frac=1, random_state=42)\n",
    "featureData2 = featureData2.sample(frac=1, random_state=42)\n",
    "\n",
    "#print(featureData1.dtypes)\n",
    "#featureData1.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m knn\u001b[39m.\u001b[39mfit(featureData, targetData)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Predict the target for the test data\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m target_pred_knn \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(shuffledFeatures)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Compute accuracy\u001b[39;00m\n\u001b[1;32m     17\u001b[0m accuracy_knn \u001b[39m=\u001b[39m accuracy_score(targetData, target_pred_knn)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    244\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_fit_method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m ArgKminClassMode\u001b[39m.\u001b[39;49mis_usable_for(\n\u001b[1;32m    247\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric\n\u001b[1;32m    248\u001b[0m     ):\n\u001b[1;32m    249\u001b[0m         probabilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    250\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_usable_for\u001b[39m(\u001b[39mcls\u001b[39m, X, Y, metric) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    450\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 471\u001b[0m         ArgKmin\u001b[39m.\u001b[39;49mis_usable_for(X, Y, metric)\n\u001b[1;32m    472\u001b[0m         \u001b[39m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    474\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(Y)\n\u001b[1;32m    475\u001b[0m         \u001b[39m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m         \u001b[39mand\u001b[39;00m metric \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msqeuclidean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    477\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[0;34m(cls, X, Y, metric)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[1;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[1;32m    104\u001b[0m         \u001b[39mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mint32\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m is_usable \u001b[39m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m     get_config()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39menable_cython_pairwise_dist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[1;32m    116\u001b[0m     \u001b[39mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[39mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[1;32m    117\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    118\u001b[0m     \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m (np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    119\u001b[0m     \u001b[39mand\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mvalid_metrics()\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m is_usable\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_numpy_c_ordered\u001b[39m(X):\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mflags\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m X\u001b[39m.\u001b[39;49mflags\u001b[39m.\u001b[39;49mc_contiguous\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "## Testing the data (our two splits)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "shuffledFeatures = featureData.sample(frac=1)#, random_state=42)\n",
    "#shuffledTargets = targetData.sample(frac=1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(featureData, targetData)\n",
    "\n",
    "# Predict the target for the test data\n",
    "target_pred_knn = knn.predict(shuffledFeatures)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_knn = accuracy_score(targetData, target_pred_knn)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_knn = f1_score(targetData, target_pred_knn)\n",
    "\n",
    "accuracy_knn, f1_knn\n",
    "\n",
    "\n",
    "## When testing with targetData2 and featureData2 we get an accuracy of 0.97647 and an F1 score of 0.97826\n",
    "## - \n",
    "\n",
    "## When testing with targetData1 and featureData1 we get an accuracy of 0.97647 and an F1 score of 0.97222\n",
    "## - NOW WITH SHUFFLED DATA: .5294117647 & 0.545454\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170,\n",
       " 55,\n",
       " 0,\n",
       " Divorce\n",
       " 0    86\n",
       " 1    84\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the dataset\n",
    "num_rows, num_cols = data.shape\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum().sum()\n",
    "\n",
    "# Check the balance of the target variable\n",
    "divorce_counts = data['Divorce'].value_counts()\n",
    "\n",
    "num_rows, num_cols, missing_values, divorce_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 170 rows (i.e., couples) and 55 columns (54 predictors and 1 target). There are no missing values in the dataset, which is good as it simplifies the preprocessing steps.\n",
    "\n",
    "The target variable \"Divorce\" is fairly balanced with 86 instances of non-divorced couples (value 0) and 84 instances of divorced couples (value 1). This is beneficial because imbalanced datasets can often lead to biased models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 54), (34, 54), (136,), (34,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop('Divorce', axis=1)#.iloc[:, :5]\n",
    "target = data['Divorce']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "features_test = scaler.transform(features_test)\n",
    "\n",
    "features_train.shape, features_test.shape, target_train.shape, target_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been successfully split into training and test sets. We have 136 instances in the training set and 34 instances in the test set. Each instance has 54 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69     1\n",
       "138    0\n",
       "2      1\n",
       "93     0\n",
       "136    0\n",
       "      ..\n",
       "71     1\n",
       "106    0\n",
       "14     1\n",
       "92     0\n",
       "102    0\n",
       "Name: Divorce, Length: 136, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '0', '0',\n",
       "       '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '0', '0'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '0', '0',\n",
       "       '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '0', '1', '1', '1', '1', '0', '0'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 54)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9705882352941176, 0.9743589743589743)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## KNN Classifier using all 54 features in the dataset\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(features_train.astype(float), target_train.astype(str))\n",
    "\n",
    "# Predict the target for the test data\n",
    "target_pred_knn = knn.predict(features_test.astype(float))\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_knn = accuracy_score(target_test.astype(str), target_pred_knn)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_knn = f1_score(target_test.astype(str), target_pred_knn,pos_label='1')\n",
    "\n",
    "accuracy_knn, f1_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_permuted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_test_permuted\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_permuted' is not defined"
     ]
    }
   ],
   "source": [
    "X_test_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Q41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Q31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Q33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Q34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Q35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Q36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Q38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Q39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Q40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Q42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Q43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Q44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Q45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Q46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Q47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Q48</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Q49</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Q50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Q51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Q52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Q53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Q29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Q16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Q21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Q54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Importance\n",
       "0       Q1         0.0\n",
       "40     Q41         0.0\n",
       "29     Q30         0.0\n",
       "30     Q31         0.0\n",
       "31     Q32         0.0\n",
       "32     Q33         0.0\n",
       "33     Q34         0.0\n",
       "34     Q35         0.0\n",
       "35     Q36         0.0\n",
       "36     Q37         0.0\n",
       "37     Q38         0.0\n",
       "38     Q39         0.0\n",
       "39     Q40         0.0\n",
       "41     Q42         0.0\n",
       "1       Q2         0.0\n",
       "42     Q43         0.0\n",
       "43     Q44         0.0\n",
       "44     Q45         0.0\n",
       "45     Q46         0.0\n",
       "46     Q47         0.0\n",
       "47     Q48         0.0\n",
       "48     Q49         0.0\n",
       "49     Q50         0.0\n",
       "50     Q51         0.0\n",
       "51     Q52         0.0\n",
       "52     Q53         0.0\n",
       "28     Q29         0.0\n",
       "27     Q28         0.0\n",
       "26     Q27         0.0\n",
       "25     Q26         0.0\n",
       "2       Q3         0.0\n",
       "3       Q4         0.0\n",
       "4       Q5         0.0\n",
       "5       Q6         0.0\n",
       "6       Q7         0.0\n",
       "7       Q8         0.0\n",
       "8       Q9         0.0\n",
       "9      Q10         0.0\n",
       "10     Q11         0.0\n",
       "11     Q12         0.0\n",
       "12     Q13         0.0\n",
       "13     Q14         0.0\n",
       "14     Q15         0.0\n",
       "15     Q16         0.0\n",
       "16     Q17         0.0\n",
       "17     Q18         0.0\n",
       "18     Q19         0.0\n",
       "19     Q20         0.0\n",
       "20     Q21         0.0\n",
       "21     Q22         0.0\n",
       "22     Q23         0.0\n",
       "23     Q24         0.0\n",
       "24     Q25         0.0\n",
       "53     Q54         0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Permutation Feature Importance on the RandomForest Classifier with all 54 features\n",
    "## - note: this may be better than KNN initially with lots of features\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Compute permutation feature importance\n",
    "perm_importance = permutation_importance(rf, features_test, target_test, n_repeats=10, random_state=42)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': perm_importance['importances_mean']\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "perm_importance_df = perm_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "perm_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we'll use a decision tree-based method to rank the importance of the features in predicting divorce. This will help us identify the key predictors of divorce.\n",
    "\n",
    "We'll use the Random Forest algorithm from scikit-learn for this. A Random Forest is an ensemble of Decision Trees that is often used for feature selection because it provides a measure of the importance of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Q40</td>\n",
       "      <td>0.096593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q17</td>\n",
       "      <td>0.095148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q18</td>\n",
       "      <td>0.091988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q19</td>\n",
       "      <td>0.089627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q12</td>\n",
       "      <td>0.089565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q20</td>\n",
       "      <td>0.063145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Q16</td>\n",
       "      <td>0.057146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q11</td>\n",
       "      <td>0.055608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q15</td>\n",
       "      <td>0.047422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q26</td>\n",
       "      <td>0.041697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Q36</td>\n",
       "      <td>0.038958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q25</td>\n",
       "      <td>0.028858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q30</td>\n",
       "      <td>0.026860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Q39</td>\n",
       "      <td>0.022693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Q29</td>\n",
       "      <td>0.020050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Q41</td>\n",
       "      <td>0.018753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q28</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Q44</td>\n",
       "      <td>0.016946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q9</td>\n",
       "      <td>0.010794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q10</td>\n",
       "      <td>0.010230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>0.009985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Q38</td>\n",
       "      <td>0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q8</td>\n",
       "      <td>0.008121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Q33</td>\n",
       "      <td>0.003204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q6</td>\n",
       "      <td>0.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Q49</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.002497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>0.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.001888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Q21</td>\n",
       "      <td>0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Q42</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q27</td>\n",
       "      <td>0.001591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q37</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Q52</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q32</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Q34</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q13</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Q31</td>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Q53</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Q51</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Q47</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Q45</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Q48</td>\n",
       "      <td>0.000443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Q46</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Q54</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Q50</td>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q24</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Q43</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Q35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Importance\n",
       "39     Q40    0.096593\n",
       "16     Q17    0.095148\n",
       "17     Q18    0.091988\n",
       "18     Q19    0.089627\n",
       "11     Q12    0.089565\n",
       "19     Q20    0.063145\n",
       "15     Q16    0.057146\n",
       "10     Q11    0.055608\n",
       "14     Q15    0.047422\n",
       "25     Q26    0.041697\n",
       "35     Q36    0.038958\n",
       "24     Q25    0.028858\n",
       "29     Q30    0.026860\n",
       "38     Q39    0.022693\n",
       "28     Q29    0.020050\n",
       "40     Q41    0.018753\n",
       "27     Q28    0.017857\n",
       "43     Q44    0.016946\n",
       "8       Q9    0.010794\n",
       "9      Q10    0.010230\n",
       "3       Q4    0.009985\n",
       "37     Q38    0.009709\n",
       "7       Q8    0.008121\n",
       "32     Q33    0.003204\n",
       "5       Q6    0.002893\n",
       "48     Q49    0.002847\n",
       "2       Q3    0.002497\n",
       "0       Q1    0.002424\n",
       "1       Q2    0.001888\n",
       "20     Q21    0.001837\n",
       "4       Q5    0.001617\n",
       "41     Q42    0.001600\n",
       "26     Q27    0.001591\n",
       "36     Q37    0.001242\n",
       "51     Q52    0.001167\n",
       "31     Q32    0.001150\n",
       "33     Q34    0.001019\n",
       "12     Q13    0.000961\n",
       "30     Q31    0.000757\n",
       "52     Q53    0.000703\n",
       "50     Q51    0.000614\n",
       "46     Q47    0.000577\n",
       "44     Q45    0.000484\n",
       "47     Q48    0.000443\n",
       "45     Q46    0.000401\n",
       "53     Q54    0.000197\n",
       "49     Q50    0.000136\n",
       "23     Q24    0.000000\n",
       "42     Q43    0.000000\n",
       "13     Q14    0.000000\n",
       "21     Q22    0.000000\n",
       "22     Q23    0.000000\n",
       "34     Q35    0.000000\n",
       "6       Q7    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m top_features \u001b[39m=\u001b[39m feature_importances[\u001b[39m'\u001b[39m\u001b[39mFeature\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     26\u001b[0m \u001b[39m# Select these top features from the training and test data\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m features_train_selected \u001b[39m=\u001b[39m features_train[top_features]\n\u001b[1;32m     28\u001b[0m features_test_selected \u001b[39m=\u001b[39m features_test[top_features]\n\u001b[1;32m     30\u001b[0m features_train_selected\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame of features and importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': features.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "display(feature_importances)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_features = feature_importances['Feature'][:10].tolist()\n",
    "\n",
    "# Select these top features from the training and test data\n",
    "features_train_selected = features_train[top_features]\n",
    "features_test_selected = features_test[top_features]\n",
    "\n",
    "features_train_selected.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest has ranked the features by their importance in predicting the target variable \"Divorce\".\n",
    "\n",
    "The five most important features, according to this model, are:\n",
    "\n",
    "Q40 with an importance of approximately 0.0966\n",
    "\n",
    "Q17 with an importance of approximately 0.0951\n",
    "\n",
    "Q18 with an importance of approximately 0.0920\n",
    "\n",
    "Q19 with an importance of approximately 0.0896\n",
    "\n",
    "Q12 with an importance of approximately 0.0896\n",
    "\n",
    "These results suggest that these questions may be particularly important in predicting divorce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "As a starting point, let's choose the top 10 features. However, we can adjust this number later if necessary. Now, let's select these top features from our training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q40  Q17  Q18  Q19  Q12  Q20  Q16  Q11  Q15  Q26\n",
       "69     0    4    4    4    4    4    4    4    4    4\n",
       "138    0    0    0    0    0    0    0    0    0    0\n",
       "2      3    3    3    3    4    2    3    3    3    2\n",
       "93     0    0    0    0    0    0    0    0    0    0\n",
       "136    0    1    0    0    1    0    0    0    0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the top 10 features\n",
    "top_features = feature_importances['Feature'][:10].tolist()\n",
    "\n",
    "# Select these top features from the training and test data\n",
    "features_train_selected = features_train[top_features]\n",
    "features_test_selected = features_test[top_features]\n",
    "\n",
    "features_train_selected.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing k-Nearest Neighbors with Scikt Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train and evaluate a k-NN model using scikit-learn, we can use the KNeighborsClassifier class. After training the model, we can use it to make predictions on the test set, and then compute accuracy and F1 score. We are only going to use the top 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_train_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m knn \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Fit the model to the training data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m knn\u001b[39m.\u001b[39mfit(features_train_selected, target_train)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(features_test_selected)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Predict the target for the test data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_train_selected' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize the KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(features_train_selected, target_train)\n",
    "\n",
    "print(features_test_selected)\n",
    "\n",
    "# Predict the target for the test data\n",
    "target_pred_knn = knn.predict(features_test_selected)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_knn = accuracy_score(target_test, target_pred_knn)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_knn = f1_score(target_test, target_pred_knn)\n",
    "\n",
    "accuracy_knn, f1_knn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbors (k-NN) model from scikit-learn achieved an accuracy of approximately 0.971 (or 97.1%) and an F1 score of approximately 0.974 on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing k-Nearest Neighbors from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to implement the k-NN algorithm from scratch. The steps are as follows:\n",
    "\n",
    "1.) Calculate Euclidean distance between two instances.\n",
    "\n",
    "\n",
    "2.) Get the k nearest neighbors of a given test instance.\n",
    "\n",
    "3.) Predict the class of the test instance by taking the mode of the class labels of the k nearest neighbors.\n",
    "\n",
    "Let's start by defining the function for calculating the Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting our DataFrames to numpy arrays will make life easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train \u001b[39m=\u001b[39m features_train\u001b[39m.\u001b[39;49mto_numpy()\n\u001b[1;32m      2\u001b[0m y_train \u001b[39m=\u001b[39m target_train\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m      3\u001b[0m X_test \u001b[39m=\u001b[39m features_test\u001b[39m.\u001b[39mto_numpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = features_train.to_numpy()\n",
    "y_train = target_train.to_numpy()\n",
    "X_test = features_test.to_numpy()\n",
    "y_test = target_test.to_numpy()\n",
    "\n",
    "print(\"Data before conversion to Numpy arrays:\")\n",
    "print(\"features_train:\")\n",
    "print(features_train.head())\n",
    "print(\"target_train:\")\n",
    "print(target_train.head())\n",
    "print(\"features_test:\")\n",
    "print(features_test.head())\n",
    "print(\"target_test:\")\n",
    "print(target_test.head())\n",
    "\n",
    "print(\"\\nData after conversion to Numpy arrays:\")\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"y_train:\")\n",
    "print(y_train)\n",
    "print(\"X_test:\")\n",
    "print(X_test)\n",
    "print(\"y_test:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    Calculate the Euclidean distance between two instances.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    - instance1: first instance\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m    - instance2: second instance\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39msum((instance1 \u001b[39m-\u001b[39m instance2) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)) \u001b[39m# subtracts corresponding elements of the two arrays\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEuclidean distance between the first and second training instance: \u001b[39m\u001b[39m{\u001b[39;00mcalculate_euclidean_distance(X_train[\u001b[39m0\u001b[39m],\u001b[39m \u001b[39mX_train[\u001b[39m1\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_euclidean_distance(instance1, instance2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two instances.\n",
    "    - instance1: first instance\n",
    "    - instance2: second instance\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((instance1 - instance2) ** 2)) # subtracts corresponding elements of the two arrays\n",
    "\n",
    "print(f\"Euclidean distance between the first and second training instance: {calculate_euclidean_distance(X_train[0], X_train[1])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll implement the function to get the k nearest neighbors of a given test instance. This function will compute the Euclidean distance from the test instance to each training instance, keep track of the k instances with the smallest distances, and return their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m nearest_neighbors\n\u001b[1;32m     16\u001b[0m \u001b[39m# Test the function\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIndices of the 3 nearest neighbors of the first test instance: \u001b[39m\u001b[39m{\u001b[39;00mget_k_nearest_neighbors(X_train,\u001b[39m \u001b[39mX_test[\u001b[39m0\u001b[39m],\u001b[39m \u001b[39m\u001b[39m3\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def get_k_nearest_neighbors(X_train, x_test, k):\n",
    "    \"\"\"\n",
    "    Get the k nearest neighbors of a test instance.\n",
    "    - X_train: training features\n",
    "    - x_test: test instance\n",
    "    - k: number of neighbors to return\n",
    "    \"\"\"\n",
    "    # Calculate the Euclidean distance from the test instance to each training instance\n",
    "    distances = np.array([calculate_euclidean_distance(x_train, x_test) for x_train in X_train])\n",
    "    \n",
    "    # Get the indices of the k training instances with the smallest distances\n",
    "    nearest_neighbors = distances.argsort()[:k]\n",
    "    \n",
    "    return nearest_neighbors\n",
    "\n",
    "# Test the function\n",
    "print(f\"Indices of the 3 nearest neighbors of the first test instance: {get_k_nearest_neighbors(X_train, X_test[0], 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we implement the function to predict the class of a test instance. This function will get the k nearest neighbors of the test instance, find the most common class label among these neighbors, and return this class label as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m prediction\n\u001b[1;32m     21\u001b[0m \u001b[39m# Test the function\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m prediction \u001b[39m=\u001b[39m predict_with_k_nearest_neighbors(X_train, y_train, X_test[\u001b[39m0\u001b[39m], \u001b[39m3\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicted class: \u001b[39m\u001b[39m{\u001b[39;00mprediction\u001b[39m}\u001b[39;00m\u001b[39m, Actual class: \u001b[39m\u001b[39m{\u001b[39;00mtarget_test\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "def predict_with_k_nearest_neighbors(X_train, y_train, x_test, k):\n",
    "    \"\"\"\n",
    "    Predict the class of a test instance using the k nearest neighbors.\n",
    "    - X_train: training features\n",
    "    - y_train: training target values\n",
    "    - x_test: test instance\n",
    "    - k: number of neighbors to consider\n",
    "    \"\"\"\n",
    "    # Get the k nearest neighbors of the test instance\n",
    "    nearest_neighbors = get_k_nearest_neighbors(X_train, x_test, k)\n",
    "    \n",
    "    # Get the class labels of the nearest neighbors\n",
    "    class_labels = y_train[nearest_neighbors]\n",
    "   \n",
    "    # Predict the most common class label\n",
    "    prediction = stats.mode(class_labels)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Test the function\n",
    "prediction = predict_with_k_nearest_neighbors(X_train, y_train, X_test[0], 3)\n",
    "print(f\"Predicted class: {prediction}, Actual class: {target_test.values[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use this function to make predictions for multiple test instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m predictions\n\u001b[1;32m     14\u001b[0m \u001b[39m# Test the function\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m predictions \u001b[39m=\u001b[39m predict_with_k_nearest_neighbors_multiple(X_train, y_train, X_test, \u001b[39m3\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicted classes: \u001b[39m\u001b[39m{\u001b[39;00mpredictions[:\u001b[39m10\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, Actual classes: \u001b[39m\u001b[39m{\u001b[39;00my_test[:\u001b[39m10\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_with_k_nearest_neighbors_multiple(X_train, y_train, X_test, k):\n",
    "    \"\"\"\n",
    "    Predict the class of multiple test instances using the k nearest neighbors.\n",
    "    - X_train: training features\n",
    "    - y_train: training target values\n",
    "    - X_test: test features\n",
    "    - k: number of neighbors to consider\n",
    "    \"\"\"\n",
    "    # Make predictions for each test instance\n",
    "    predictions = [predict_with_k_nearest_neighbors(X_train, y_train, x_test, k) for x_test in X_test]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Test the function\n",
    "predictions = predict_with_k_nearest_neighbors_multiple(X_train, y_train, X_test, 3)\n",
    "print(f\"Predicted classes: {predictions[:10]}, Actual classes: {y_test[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom implementation of the k-Nearest Neighbors (k-NN) algorithm is working correctly. It made correct predictions for the first 10 instances in the test set!\n",
    "\n",
    "\n",
    "Now that we have implemented and tested the k-NN algorithm from scratch, let's evaluate its performance on the entire test set. We'll compute the accuracy and F1 score as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Make predictions for the entire test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[39m=\u001b[39m predict_with_k_nearest_neighbors_multiple(X_train, y_train, X_test, \u001b[39m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Compute accuracy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m accuracy_knn_custom \u001b[39m=\u001b[39m accuracy_score(y_test, predictions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions for the entire test set\n",
    "predictions = predict_with_k_nearest_neighbors_multiple(X_train, y_train, X_test, 3)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_knn_custom = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_knn_custom = f1_score(y_test, predictions)\n",
    "\n",
    "accuracy_knn_custom, f1_knn_custom\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom implementation of the k-Nearest Neighbors (k-NN) algorithm achieved an accuracy of approximately 0.971 (or 97.1%) and an F1 score of approximately 0.974 on the test data. These values are quite high and turned out to be the same as the scikit-learn k-NN. Now, let's compute the permutation feature importance for both the scikit-learn and custom k-NN models.\n",
    "\n",
    "# Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q46</th>\n",
       "      <th>Q47</th>\n",
       "      <th>Q48</th>\n",
       "      <th>Q49</th>\n",
       "      <th>Q50</th>\n",
       "      <th>Q51</th>\n",
       "      <th>Q52</th>\n",
       "      <th>Q53</th>\n",
       "      <th>Q54</th>\n",
       "      <th>Divorce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  Q46  Q47  Q48  Q49  Q50  \\\n",
       "0     2   2   4   1   0   0   0   0   0    0  ...    2    1    3    3    3   \n",
       "1     4   4   4   4   4   0   0   4   4    4  ...    2    2    3    4    4   \n",
       "2     2   2   2   2   1   3   2   1   1    2  ...    3    2    3    1    1   \n",
       "3     3   2   3   2   3   3   3   3   3    3  ...    2    2    3    3    3   \n",
       "4     2   2   1   1   1   1   0   0   0    0  ...    2    1    2    3    2   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "165   0   0   0   0   0   0   0   0   0    0  ...    1    0    4    1    1   \n",
       "166   0   0   0   0   0   0   0   0   0    0  ...    4    1    2    2    2   \n",
       "167   1   1   0   0   0   0   0   0   0    1  ...    3    0    2    0    1   \n",
       "168   0   0   0   0   0   0   0   0   0    0  ...    3    3    2    2    3   \n",
       "169   0   0   0   0   0   0   0   1   0    0  ...    3    4    4    0    1   \n",
       "\n",
       "     Q51  Q52  Q53  Q54  Divorce  \n",
       "0      2    3    2    1        1  \n",
       "1      4    4    2    2        1  \n",
       "2      1    2    2    2        1  \n",
       "3      3    2    2    2        1  \n",
       "4      2    2    1    0        1  \n",
       "..   ...  ...  ...  ...      ...  \n",
       "165    4    2    2    2        0  \n",
       "166    2    3    2    2        0  \n",
       "167    1    3    0    0        0  \n",
       "168    2    4    3    1        0  \n",
       "169    3    3    3    1        0  \n",
       "\n",
       "[170 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9705882352941176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q45</th>\n",
       "      <th>Q46</th>\n",
       "      <th>Q47</th>\n",
       "      <th>Q48</th>\n",
       "      <th>Q49</th>\n",
       "      <th>Q50</th>\n",
       "      <th>Q51</th>\n",
       "      <th>Q52</th>\n",
       "      <th>Q53</th>\n",
       "      <th>Q54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  Q45  Q46  Q47  Q48  Q49  \\\n",
       "0     2   2   4   1   0   0   0   0   0    0  ...    3    2    1    3    3   \n",
       "1     4   4   4   4   4   0   0   4   4    4  ...    2    2    2    3    4   \n",
       "2     2   2   2   2   1   3   2   1   1    2  ...    2    3    2    3    1   \n",
       "3     3   2   3   2   3   3   3   3   3    3  ...    3    2    2    3    3   \n",
       "4     2   2   1   1   1   1   0   0   0    0  ...    2    2    1    2    3   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "165   0   0   0   0   0   0   0   0   0    0  ...    0    1    0    4    1   \n",
       "166   0   0   0   0   0   0   0   0   0    0  ...    3    4    1    2    2   \n",
       "167   1   1   0   0   0   0   0   0   0    1  ...    2    3    0    2    0   \n",
       "168   0   0   0   0   0   0   0   0   0    0  ...    4    3    3    2    2   \n",
       "169   0   0   0   0   0   0   0   1   0    0  ...    1    3    4    4    0   \n",
       "\n",
       "     Q50  Q51  Q52  Q53  Q54  \n",
       "0      3    2    3    2    1  \n",
       "1      4    4    4    2    2  \n",
       "2      1    1    2    2    2  \n",
       "3      3    3    2    2    2  \n",
       "4      2    2    2    1    0  \n",
       "..   ...  ...  ...  ...  ...  \n",
       "165    1    4    2    2    2  \n",
       "166    2    2    3    2    2  \n",
       "167    1    1    3    0    0  \n",
       "168    3    2    4    3    1  \n",
       "169    1    3    3    3    1  \n",
       "\n",
       "[170 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "165    0\n",
       "166    0\n",
       "167    0\n",
       "168    0\n",
       "169    0\n",
       "Name: Divorce, Length: 170, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 0.0\n",
      "Q2: 0.0\n",
      "Q3: 0.0\n",
      "Q4: 0.0\n",
      "Q5: 0.0\n",
      "Q6: 0.0\n",
      "Q7: 0.0\n",
      "Q8: 0.0\n",
      "Q9: 0.0\n",
      "Q10: 0.0\n",
      "Q11: 0.0\n",
      "Q12: 0.0\n",
      "Q13: 0.0\n",
      "Q14: 0.0\n",
      "Q15: 0.0\n",
      "Q16: 0.0\n",
      "Q17: 0.0\n",
      "Q18: 0.0\n",
      "Q19: 0.0\n",
      "Q20: 0.0\n",
      "Q21: 0.0\n",
      "Q22: 0.0\n",
      "Q23: 0.0\n",
      "Q24: 0.0\n",
      "Q25: 0.0\n",
      "Q26: 0.0\n",
      "Q27: 0.0\n",
      "Q28: 0.0\n",
      "Q29: 0.0\n",
      "Q30: 0.0\n",
      "Q31: 0.0\n",
      "Q32: 0.0\n",
      "Q33: 0.0\n",
      "Q34: 0.0\n",
      "Q35: 0.0\n",
      "Q36: 0.0\n",
      "Q37: 0.0\n",
      "Q38: 0.0\n",
      "Q39: 0.0\n",
      "Q40: 0.0021568627450980317\n",
      "Q41: 0.0\n",
      "Q42: 0.0\n",
      "Q43: 0.0\n",
      "Q44: 0.0\n",
      "Q45: 0.0\n",
      "Q46: 0.0\n",
      "Q47: 0.0\n",
      "Q48: 0.0\n",
      "Q49: 0.0\n",
      "Q50: 0.0\n",
      "Q51: 0.0\n",
      "Q52: 0.0\n",
      "Q53: 0.0\n",
      "Q54: 0.0\n"
     ]
    }
   ],
   "source": [
    "## Importing the dataset\n",
    "data = pd.read_csv('data/divorce_data.csv', sep=';')\n",
    "display(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop('Divorce', axis=1)\n",
    "target = data['Divorce']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "# Fit the model to the training data\n",
    "rf.fit(features_train, target_train)\n",
    "# Evaluate the model on the test data\n",
    "accuracy_rf = rf.score(features_test, target_test)\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "\n",
    "\n",
    "# Let's start with scikit learn's implementation\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "display(features)\n",
    "display(target)\n",
    "\n",
    "# Compute permutation feature importance\n",
    "result = permutation_importance(rf, features, target, n_repeats=30, random_state=42)\n",
    "\n",
    "importances = result['importances_mean']\n",
    "\n",
    "for feature_name, importance in zip(features_test.columns, importances):\n",
    "    print(f\"{feature_name}: {importance}\")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Create a new RandomForestClassifier\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# # Fit the model to the training data\n",
    "# rf.fit(features_train, target_train)\n",
    "# # Evaluate the model on the test data\n",
    "# accuracy_rf = rf.score(features_test, target_test)\n",
    "# print(f\"Accuracy: {accuracy_rf}\")\n",
    "\n",
    "# # Perform cross-validation and compute permutation feature importance\n",
    "# cv_results = cross_val_score(rf, features, target, cv=5, scoring='accuracy')\n",
    "# print(\"Cross-validation Accuracy:\", cv_results.mean())\n",
    "\n",
    "# # Compute permutation feature importance on the entire dataset\n",
    "# result = permutation_importance(rf, features, target, n_repeats=30, random_state=42)\n",
    "# importances = result['importances_mean']\n",
    "\n",
    "# # Print feature importances\n",
    "# for feature_name, importance in zip(features.columns, importances):\n",
    "#     print(f\"{feature_name}: {importance}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divorce Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Divorce Predictor. Please answer the following questions about your relationship.\n",
      "Your responses should be one of the following: 0 (Never), 1 (Seldom), 2 (Averagely), 3 (Frequently), 4 (Always)\n",
      "Please respond as honestly as possible.\n",
      "\n",
      "Question 1: I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.\n",
      "Question 2: My spouse and I have similar values in terms of personal freedom.\n",
      "Question 3: Our dreams with my spouse are similar and harmonious.\n",
      "Question 4: We're compatible with my spouse about what love should be.\n",
      "Question 5: We share the same views about being happy in our life with my spouse\n",
      "Question 6: My spouse and I have similar ideas about how marriage should be\n",
      "Question 7: My spouse and I have similar ideas about how roles should be in marriage\n",
      "Question 8: My spouse and I have similar values in trust.\n",
      "Question 9: I know my spouse's basic anxieties.\n",
      "Question 10: We're just starting a discussion before I know what's going on.\n",
      "\n",
      "Thank you for your responses. The model is now making a prediction...\n",
      "\n",
      "The model predicts that the couple will not get divorced.\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to the Divorce Predictor. Please answer the following questions about your relationship.\")\n",
    "print(\"Your responses should be one of the following: 0 (Never), 1 (Seldom), 2 (Averagely), 3 (Frequently), 4 (Always)\")\n",
    "print(\"Please respond as honestly as possible.\\n\")\n",
    "\n",
    "questions_df = pd.read_csv('data/reference.tsv', delimiter='|', header=None, names=['attribute_id', 'description'])\n",
    "\n",
    "selected_feature_names = ['Q40', 'Q17', 'Q18', 'Q19', 'Q12', 'Q20', 'Q16', 'Q11', 'Q15', 'Q26']\n",
    "\n",
    "\n",
    "# Correct the attribute IDs and re-extract the selected questions\n",
    "corrected_ids = [str(int(x[1:])) for x in selected_feature_names]\n",
    "selected_questions = questions_df[questions_df['attribute_id'].isin(corrected_ids)]\n",
    "\n",
    "# Get the questions in a list\n",
    "selected_questions_list = selected_questions['description'].tolist()\n",
    "\n",
    "# Display the selected questions\n",
    "selected_questions_list\n",
    "\n",
    "# List of top 10 most important questions\n",
    "questions = selected_questions_list  # replace with the list of the top 10 questions\n",
    "\n",
    "# List to store the user's responses\n",
    "responses = []\n",
    "\n",
    "# Ask the user to input their responses\n",
    "for i, question in enumerate(questions, start=1):\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    response = input(\"Your response (0-4): \")\n",
    "    while not response.isdigit() or int(response) not in range(5):\n",
    "        print(\"Invalid response. Please enter a number from 0 to 4.\")\n",
    "        response = input(\"Your response (0-4): \")\n",
    "    responses.append(int(response))\n",
    "\n",
    "print(\"\\nThank you for your responses. The model is now making a prediction...\\n\")\n",
    "\n",
    "# Convert the responses into a format that can be used for prediction\n",
    "responses_df = pd.DataFrame([responses], columns=selected_feature_names)\n",
    "\n",
    "# Use the trained model to make a prediction\n",
    "prediction = knn.predict(responses_df)\n",
    "\n",
    "# Display the prediction\n",
    "if prediction == 0:\n",
    "    print(\"The model predicts that the couple will not get divorced.\")\n",
    "else:\n",
    "    print(\"The model predicts that the couple will get divorced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
